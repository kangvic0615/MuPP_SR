# general
gpu_id: 0
use_gpu: True
seed: 2120
state: INFO
reproducibility: True
data_path: 'dataset'
checkpoint_dir: 'RecBole/saved'
show_progress: True
save_dataset: False
save_dataloaders: False

# dataset
load_col:
    inter: [user_id, item_id, rating, timestamp]
    # item: ['item_id','title','sales_rank','price','brand','categories','sales_type']
MAX_ITEM_LIST_LENGTH: 50
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
RATING_FIELD: rating
TIME_FIELD: timestamp

# Filtering
val_interval: ~
filter_inter_by_user_or_item: True
user_inter_num_interval: "[5,inf)"
item_inter_num_interval: "[5,inf)"

# Model
n_layers: 4
n_heads: 8
hidden_size: 256
inner_size: 256

embedding_size: 256
mask_ratio: 0.2
ft_ratio: 0.5

hidden_dropout_prob: 0.5
attn_dropout_prob: 0.5 
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.02
pooling_mode: 'sum' # sum, mean, max
loss_type: 'CE'

num_item_representation: 2

# training settings
epochs: 300
train_batch_size: 4096
learner: adam
learning_rate: 0.0005
eval_step: 2
stopping_step: 5
clip_grad_norm: ~
weight_decay: 0.0
# neg_sampling: 
train_neg_sample_args: ~

# evaluation settings
eval_args:
  split: { 'RS':[0.8,0.1,0.1] }
  group_by: user
  order: TO
  mode: full



repeatable: True
metrics: ["NDCG","MRR"] 
topk: [3,5,10,20]
valid_metric: NDCG@20
valid_metric_bigger: True
eval_batch_size: 512
loss_decimal_place: 4
metric_decimal_place: 4